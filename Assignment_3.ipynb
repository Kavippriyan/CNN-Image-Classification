{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Compare your network with state-of-the-art networks"
      ],
      "metadata": {
        "id": "Z32ooOtwdLiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Choose two state-of-the-art pre-trained model\n",
        "13. Load the pre-trained model and fine-tune it for the your dataset"
      ],
      "metadata": {
        "id": "fFL6ZnXAdPit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50, VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Adjust MNIST images to RGB for pretrained models\n",
        "train_images_rgb = np.repeat(train_images, 3, axis = -1)\n",
        "val_images_rgb = np.repeat(val_images, 3, axis = -1)\n",
        "test_images_rgb = np.repeat(test_images, 3, axis = -1)\n",
        "\n",
        "# Resize images to 32x32\n",
        "train_images_rgb = tf.image.resize(train_images_rgb, [32, 32])\n",
        "val_images_rgb = tf.image.resize(val_images_rgb, [32, 32])\n",
        "test_images_rgb = tf.image.resize(test_images_rgb, [32, 32])\n",
        "\n",
        "# Function to build and fine-tune a model\n",
        "def build_fine_tune_model(base_model, input_shape, trainable = False):\n",
        "    # Freeze the base model layers\n",
        "    base_model.trainable = trainable\n",
        "\n",
        "    # Build the model\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation = 'relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation = 'softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load pretrained ResNet50\n",
        "resnet_base = ResNet50(weights = 'imagenet', include_top = False, input_shape = (32, 32, 3))\n",
        "resnet_model = build_fine_tune_model(resnet_base, input_shape = (32, 32, 3))\n",
        "\n",
        "# Compile the ResNet model\n",
        "resnet_model.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "# Load pretrained VGG16\n",
        "vgg_base = VGG16(weights='imagenet', include_top = False, input_shape = (32, 32, 3))\n",
        "vgg_model = build_fine_tune_model(vgg_base, input_shape = (32, 32, 3))\n",
        "\n",
        "# Compile the VGG model\n",
        "vgg_model.compile(optimizer = Adam(learning_rate = 0.0005), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "LqOyuMWXdS1-",
        "outputId": "ac7d97e8-5187-404e-bce9-aade75175e28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fdfc3680980a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Adjust MNIST images to RGB for pretrained models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_images_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mval_images_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_images_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Train the fine-tuned model using the same training and testing data split as your custom CNN model\n",
        "15. Record training and validation loss values for each epoch"
      ],
      "metadata": {
        "id": "Bh0SrhqfdVkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train ResNet50\n",
        "history_resnet = resnet_model.fit(train_images_rgb, train_labels, validation_data = (val_images_rgb, val_labels), epochs = 10, batch_size = 1024)\n",
        "\n",
        "# Train VGG16\n",
        "history_vgg = vgg_model.fit(train_images_rgb, train_labels, validation_data = (val_images_rgb, val_labels), epochs = 10, batch_size = 1024)\n"
      ],
      "metadata": {
        "id": "UjdrOLR6dYZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. Evaluate the fine-tuned model on the testing dataset and calculate the test accuracy"
      ],
      "metadata": {
        "id": "3wzNuMnpda8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and Compare Both Models\n",
        "resnet_test_loss, resnet_test_accuracy = resnet_model.evaluate(test_images_rgb, test_labels)\n",
        "vgg_test_loss, vgg_test_accuracy = vgg_model.evaluate(test_images_rgb, test_labels)\n",
        "\n",
        "print(f\"ResNet50 Test Accuracy: {resnet_test_accuracy:.4f}\")\n",
        "print(f\"VGG16 Test Accuracy: {vgg_test_accuracy:.4f}\")\n",
        "\n",
        "# Plot Training and Validation Loss for ResNet\n",
        "plt.plot(history_resnet.history['loss'], label = 'ResNet Training Loss')\n",
        "plt.plot(history_resnet.history['val_loss'], label = 'ResNet Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title(\"ResNet50 Loss\")\n",
        "plt.show()\n",
        "\n",
        "# Plot Training and Validation Loss for VGG16\n",
        "plt.plot(history_vgg.history['loss'], label = 'VGG Training Loss')\n",
        "plt.plot(history_vgg.history['val_loss'], label = 'VGG Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title(\"VGG16 Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JoDtnIJvdd2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and Generate Confusion Matrices\n",
        "def plot_confusion_matrix(model, test_images, test_labels, model_name):\n",
        "    predictions = model.predict(test_images)\n",
        "    predicted_classes = np.argmax(predictions, axis = 1)\n",
        "    conf_matrix = confusion_matrix(test_labels, predicted_classes)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Classification Report for {model_name}:\")\n",
        "    print(classification_report(test_labels, predicted_classes, target_names=[str(i) for i in range(10)]))\n",
        "\n",
        "# ResNet Confusion Matrix and Report\n",
        "plot_confusion_matrix(resnet_model, test_images_rgb, test_labels, \"ResNet50\")\n",
        "\n",
        "# VGG Confusion Matrix and Report\n",
        "plot_confusion_matrix(vgg_model, test_images_rgb, test_labels, \"VGG16\")\n"
      ],
      "metadata": {
        "id": "rVgzXaSyiu1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}